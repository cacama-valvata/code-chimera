I collected the different methods proposed here, and in two [other][1] [questions][2], and measured the speed of the different methods:

    import numpy as np
    import scipy.spatial
    import sklearn.metrics
    
    def dist_direct(x, y):
        d = np.expand_dims(x, -2) - y
        return np.sum(np.square(d), axis=-1)
    
    def dist_einsum(x, y):
        d = np.expand_dims(x, -2) - y
        return np.einsum('ijk,ijk->ij', d, d)
    
    def dist_scipy(x, y):
        return scipy.spatial.distance.cdist(x, y, "sqeuclidean")
    
    def dist_sklearn(x, y):
        return sklearn.metrics.pairwise.pairwise_distances(x, y, "sqeuclidean")
    
    def dist_layers(x, y):
        res = np.zeros((x.shape[0], y.shape[0]))
        for i in range(x.shape[1]):
            res += np.subtract.outer(x[:, i], y[:, i])**2
        return res
    
    # inspired by the excellent https://github.com/droyed/eucl_dist
    def dist_ext1(x, y):
        nx, p = x.shape
        x_ext = np.empty((nx, 3*p))
        x_ext[:, :p] = 1
        x_ext[:, p:2*p] = x
        x_ext[:, 2*p:] = np.square(x)
    
        ny = y.shape[0]
        y_ext = np.empty((3*p, ny))
        y_ext[:p] = np.square(y).T
        y_ext[p:2*p] = -2*y.T
        y_ext[2*p:] = 1
    
        return x_ext.dot(y_ext)
    
    # https://stackoverflow.com/a/47877630/648741
    def dist_ext2(x, y):
        return np.einsum('ij,ij->i', x, x)[:,None] + np.einsum('ij,ij->i', y, y) - 2 * x.dot(y.T)

I use `timeit` to compare the speed of the different methods.  For the comparison, I use vectors of length 10, with 100 vectors in the first group, and 1000 vectors in the second group.

    import timeit
    
    p = 10
    x = np.random.standard_normal((100, p))
    y = np.random.standard_normal((1000, p))
    
    for method in dir():
        if not method.startswith("dist_"):
            continue
        t = timeit.timeit(f"{method}(x, y)", number=1000, globals=globals())
        print(f"{method:12} {t:5.2f}ms")

On my laptop, the results are as follows:

    dist_direct   5.07ms
    dist_einsum   3.43ms
    dist_ext1     0.20ms  <-- fastest
    dist_ext2     0.35ms
    dist_layers   2.82ms
    dist_scipy    0.60ms
    dist_sklearn  0.67ms

While the two methods `dist_ext1` and `dist_ext2`, both based on the idea of writing `(x-y)**2` as `x**2 - 2*x*y + y**2`, are very fast, there is a downside: When the distance between `x` and `y` is very small, due to [cancellation error][3] the numerical result can sometimes be (very slightly) negative.

  [1]: https://stackoverflow.com/q/56082945/648741
  [2]: https://stackoverflow.com/q/47877530/648741
  [3]: https://en.wikipedia.org/wiki/Loss_of_significance